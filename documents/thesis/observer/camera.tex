\subsection{Camera}
\label{ssec:observer:sensormodels:camera}
    To estimate the position of the camera using the captured images,
    the PTAM-library is used.
    The main application of the PTAM library is reprojection of
    augmented reality into the video stream.
    This means that consistency between a metric world-fixed
    coordinate frame (such as the NEDEF-system used on the LinkQuad), and the
    internally used coordinate system is not necessary for its application.
    The transformation between the NEDEF coordinate system and the
    PTAM coordinate system thus have to be determined.

    The measurements from the camera consists of the transform from the PTAM ``world''-coordinates
    to the camera lens, in terms of
    \begin{itemize}
        \item translation, $X^{\text{PTAM}}$,
        \item and orientation, $q^{PTAM,c}$.
    \end{itemize}
    A rough estimate of the quality of the tracking is also provided as an enumerated representation of either \textit{Good}, \textit{Poor} or \textit{Bad}.
    However, since the quite arbitrary \citep{klein07parallel} coordinate system
    of PTAM is neither of the same scale nor aligned with the quadrotor coordinate system,
    we need to estimate the affine transformation between the two in order to get useful results.

    Since both the NEDEF and the PTAM coordinate frame is world-fixed, the transformation is characterized by
    \begin{itemize}
        \item a translation T to the origin, $\varnothing_{\text{PTAM}}$,
        \item a rotation R by the quaternion $q^{Pw}$,
        \item and a scaling S by a factor $s$.
    \end{itemize}
    %~ \begin{equation}
        %~ x_{\text{world}} = \underbrace{R(q^{wb})}_{quadrotor orientation} * \underbrace{T(\varnothing_{\text{cam}}) R(q^{bc}) S(s)}_{quadrotor to PTAM transform} x_{\text{cam}}
    %~ \end{equation}
    These are collected to a single transformation in Eq.~\ref{eq:observer:sensormodels:camera:transformation},
    forming the full transformation from the global NEDEF system to the
    PTAM coordinate frame.
    \begin{equation}
        \label{eq:observer:sensormodels:camera:transformation}
        x^{\text{PTAM}} = \underbrace{S(s) R(q^{Pw}) T(-\varnothing_{\text{PTAM}})}_{\triangleq \mathcal{J}^{Pw}, \text{transformation from camera to PTAM}}
         x^{\text{NEDEF}}
    \end{equation}

    The offline case of this problem is partially studied in \citep{hayashi2010},
    whereas the method used in this thesis can be extended to the on-line
    case where no ground truth is available by introducing continuously improved
    states to the observer filter, using the first measurement to construct
    an initial guess.

    While PTAM exhibits very stable positioning, it has a tendency to move
    its origin due to association errors. To provide stable position
    measurements, those movements should be detected and the
    camera transformation adjusted accordingly.
    Initialization and tracking is dealt with in
    Section~\ref{sssec:observer:sensormodels:camera:initialization} and \ref{sssec:observer:sensormodels:camera:refinement}
    respectively, whereas the teleportation problem is discussed in
    Section~\ref{sssec:observer:sensormodels:camera:teleportation}.

    \subsubsection{Initialization}
        \label{sssec:observer:sensormodels:camera:initialization}
        When the first camera measurement arrives, there is a need to construct a
        first guess of the transform. Since the PTAM initialization places
        the origin at what it considers the ground level, the most informed
        guess we can do without any information about the environment is
        to assume that this is a horizontal plane at zero height.

        The orientation of the PTAM coordinate system is calculated as in Eq. \eqref{eq:observer:sensormodels:camera:qpw}
        from the estimated quadrotor orientation and the measurement in the
        PTAM coordinate frame.
        \begin{equation}
            \label{eq:observer:sensormodels:camera:qpw}
            q^{Pw} = q^{PTAM,c} q^{cb} q^{bw}
        \end{equation}

        $q^{bc}$, the inverse of $q^{cb}$ of Equation~\ref{eq:observer:sensormodels:camera:qpw},
        describes the rotation from camera coordinates to body-fixed coordinates, taking
        into account the differing definitions between the PTAM library
        camera coordinate system and that used in this thesis.
        With known camera pitch and yaw - $\Theta_{c}$ and $\Psi_{c}$ respectively -
        this  corresponds to four consecutive rotations, given in
        Eq.~\eqref{eq:observer:sensormodels:qbc} as rotations around gives axes.

        %~ Quaternion<double> qbc(
            %~ AngleAxis<double>(config["camera"]["tilt"].as<double>(), Vector3d::UnitY())
            %~ * AngleAxis<double>(config["camera"]["yaw"].as<double>(), Vector3d::UnitZ())
            %~ * AngleAxis<double>(M_PI_2, Vector3d::UnitZ())
            %~ * AngleAxis<double>(M_PI_2, Vector3d::UnitX()));
        \begin{equation}
        \label{eq:observer:sensormodels:qbc}
            q^{bc} = \text{rot}(\Theta_{c}, \hat{y}) \cdot \text{rot}(\Psi_{c}, \hat{z}) \cdot \text{rot}(\pi/2, \hat{z}) \cdot \text{rot}(\pi/2, \hat{x})
        \end{equation}

        To determine the distance to this plane according to the current estimation,
        Equation \eqref{eq:observer:sensormodels:camera:origin} is solved for $\lambda$
        in accordance with Eq.~\ref{eq:observer:sensormodels:camera:lambda}.
        \begin{equation}
            \label{eq:observer:sensormodels:camera:origin}
            \left\lbrace
            \begin{array}{ll}
                \varnothing_{\text{PTAM}} &= \xi + R(q^{wb}) r_{\text{camera}/\mathcal{G}} + \lambda R(q^{wP}) \frac{X^{PTAM}}{|X^{PTAM}|} \\
                \varnothing_{\text{PTAM}} \cdot \hat{z} &= 0
            \end{array}\right.
        \end{equation}

        \begin{equation}
            \label{eq:observer:sensormodels:camera:lambda}
            \lambda = -\frac{\left(\xi + R(q^{wb}) r_{\text{camera}/\mathcal{G}} \right) \cdot \hat{z}}{\left( R(q^{wP}) \frac{X^{PTAM}}{|X^{PTAM}|} \right) \cdot \hat{z}}
        \end{equation}

        \fig{\plotwidth}{ground}{The PTAM coordinate system is assumed to be positioned at zero height. $\lambda$ is calculated as the estimated real-world distance to the PTAM coordinate system.}{fig:ground}


        With this definition, $\lambda$ corresponds to the approximated distance
        from the camera to the PTAM origin, in the metric world-fixed coordinate system.
        By comparing this approximation with the distance measured
        in the PTAM coordinate system, we obtain an estimate for the scaling factor, $s$, given
        in Eq.~\ref{eq:observer:camera:s}.
        \begin{equation}
        \label{eq:observer:camera:s}
            s = \frac{|X^{PTAM}|}{|\lambda|}
        \end{equation}

        Together, these parameters describes the transformation
        connecting the PTAM reference frame to the metric world.
        For further refinement, the parameters could be inserted into the
        global observer filter - introducing eight new states containing
        $q^{Pw}$, $s$ and $\varnothing_{\text{cam}}$ - although little benefit
        of this has been observed in simulated testing.
        Because the PTAM coordinate system is defined fixed in the global NEDEF coordinate system,
        the transform parameters are unchanged in the observer's time update.

    \subsubsection{Camera Measurements}
        \label{sssec:observer:sensormodels:camera:refinement}
        The measurement update is made separate from the update of the inertial sensors, using
        the measurement equations in \eqref{eq:observer:measurement:camera}, expanding the
        equation derived in Eqs. \eqref{eq:observer:sensormodels:camera:transformation} and \eqref{eq:observer:sensormodels:camera:qpw}.

        \begin{subequations}
            \label{eq:observer:measurement:camera}
            \begin{align}
                \hat{X}^{\text{PTAM}} &= \mathcal{J}^{Pw} (\xi + R(q^{wb})r_{\text{camera}/\mathcal{G}}) + e_{\text{PTAM,X}} \\
                \hat{q}^{\text{PTAM,c}} &= q^{Pw} q^{wb} q^{bc} + e_{\text{PTAM,q}}
            \end{align}
        \end{subequations}

    \subsubsection{Teleportation}
        \label{sssec:observer:sensormodels:camera:teleportation}
        The PTAM tracking may sometimes exhibit a ``teleporting'' behavior.
        That is, although tracking is overall stable, the origin may
        sometimes be misassociated and placed at a new position as the
        tracking gets lost.
        To detect this, the measurements may be monitored for sudden changes in position.
        If a teleportation is detected, a reinitialization would be needed,
        either performing a new initial estimation, or utilizing the previous state
        to recognize the new pose of the origin.
        The teleporting behavior is currently detected using simple thresholding,
        as in Eq.~\eqref{eq:observer:sensormodels:camera:teleport},
        although no action is currently implemented to recover.
        In Eq.~\eqref{eq:observer:sensormodels:camera:teleport}, the
        estimated motion is scaled by the factor $s$ from the transformation
        from PTAM coordinates, and thresholded by a configurable parameter $\epsilon$.
        \begin{equation}
            \label{eq:observer:sensormodels:camera:teleport}
            \left|X^{\text{PTAM}}_{t} - X^{\text{PTAM}}_{t-1}\right| \cdot s > \epsilon
        \end{equation}
