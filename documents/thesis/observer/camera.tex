\subsection{Camera}
\label{ssec:observer:sensormodels:camera}
    To estimate the position of the camera using the captured images,
    the PTAM camera positioning library presented in Chapter~\ref{cha:monoslam} is used.
    The main application of the PTAM library is reprojection of
    augmented reality into a video stream.
    Consistency between a metric world-fixed coordinate frame
    (such as the NEDEF-system used on the LinkQuad), and the, quite arbitrarily placed~\citep{klein07parallel},
    internally used coordinate system is not vital for its intended operation,
    although to position the camera in the real world, it is.
    The transformation between the NEDEF coordinate system and the
    PTAM coordinate system thus has to be determined to attain useful measurements.

    The measurements from the camera consists of the transform from PTAM's coordinates
    to the camera lens, in terms of
    \begin{itemize}
        \item Translation\footnote{Notably, the translation is of arbitrary, initially unknown, scale.}, $X^{\text{PTAM}}$,
        \item Orientation, $q^{PTAM,c}$.
    \end{itemize}
    A rough estimate of the quality of the tracking is also provided as an enumerated representation of either \textit{Good}, \textit{Poor} or \textit{Bad}.
    Since the coordinate system of PTAM is neither of the same scale nor aligned with the quadrotor's coordinate system,
    the affine transformation between the two must be estimated.

    Since both the NEDEF and the PTAM coordinate frame is world-fixed,
    the transformation is ideally static and characterized by
    \begin{itemize}
        \item a translation T to the origin, $\varnothing_{\text{PTAM}}$,
        \item a rotation R by the quaternion $q^{Pw}$,
        \item a scaling S by a factor $s$.
    \end{itemize}
    %~ \begin{equation}
        %~ x_{\text{world}} = \underbrace{R(q^{wb})}_{quadrotor orientation} * \underbrace{T(\varnothing_{\text{cam}}) R(q^{bc}) S(s)}_{quadrotor to PTAM transform} x_{\text{cam}}
    %~ \end{equation}
    These are collected to a single transformation in Eq.~\ref{eq:observer:sensormodels:camera:transformation},
    forming the full transformation from the global NEDEF system to the
    PTAM coordinate frame.
    \begin{equation}
        \label{eq:observer:sensormodels:camera:transformation}
        x^{\text{PTAM}} = \underbrace{S(s) R(q^{Pw}) T(-\varnothing_{\text{PTAM}})}_{\triangleq \mathcal{J}^{Pw}, \text{transformation from camera to PTAM}}
         x^{\text{NEDEF}}
    \end{equation}

    The offline case of this problem is partially studied in \citep{hayashi2010},
    whereas the method used in this thesis can be extended to the on-line
    case where no ground truth is available by introducing continuously improved
    states to the observer filter, using the first measurement to construct
    an initial guess.

    %~ While PTAM exhibits very stable positioning, it has a tendency to move
    %~ its origin due to association errors. To provide stable position
    %~ measurements, those movements should be detected and the
    %~ camera transformation adjusted accordingly, as discussed below.
    %~ Initialization and tracking is dealt with in
    %~ Section~\ref{sssec:observer:sensormodels:camera:initialization} and \ref{sssec:observer:sensormodels:camera:refinement}
    %~ respectively, whereas the teleportation problem is discussed in
    %~ Section~\ref{sssec:observer:sensormodels:camera:teleportation}.

    \subsubsection{Initialization}
        \label{sssec:observer:sensormodels:camera:initialization}
        When the first camera measurement arrives, there is a need to construct
        the world-to-PTAM transformation.
        Since the PTAM initialization places the origin at what it
        considers the ground level, the most informed guess we can do
        without any further information about the environment, is
        to assume that this is a horizontal plane at zero height.

        The orientation of the PTAM coordinate system is calculated,
        using quaternion multiplication, as in Eq. \eqref{eq:observer:sensormodels:camera:qpw}
        from the estimated quadrotor orientation and the measurement in the
        PTAM coordinate frame, $q^{PTAM,c}$.
        \begin{equation}
            \label{eq:observer:sensormodels:camera:qpw}
            q^{Pw} = q^{PTAM,c} q^{cb} q^{bw}
        \end{equation}

        The quaternion $q^{bc}$, the inverse of $q^{cb}$ of Equation~\ref{eq:observer:sensormodels:camera:qpw},
        describes the rotation from camera coordinates to body-fixed coordinates.
        With known camera pitch and yaw, $\Theta_{c}$ and $\Psi_{c}$ respectively,
        this corresponds to four consecutive rotations, given in
        Eq.~\eqref{eq:observer:sensormodels:qbc} as rotations around gives axes,
        the last two rotations accounting for the differing definitions between the PTAM library
        camera coordinate system ($\hat{z}$ upwards) and that used in this thesis ($\hat{z}$ downwards).

        %~ Quaternion<double> qbc(
            %~ AngleAxis<double>(config["camera"]["tilt"].as<double>(), Vector3d::UnitY())
            %~ * AngleAxis<double>(config["camera"]["yaw"].as<double>(), Vector3d::UnitZ())
            %~ * AngleAxis<double>(M_PI_2, Vector3d::UnitZ())
            %~ * AngleAxis<double>(M_PI_2, Vector3d::UnitX()));
        \begin{equation}
        \label{eq:observer:sensormodels:qbc}
            q^{bc} = \text{R}(\Theta_{c}, \hat{y}) \cdot \text{R}(\Psi_{c}, \hat{z}) \cdot \text{R}(\pi/2, \hat{z}) \cdot \text{R}(\pi/2, \hat{x})
        \end{equation}

        To determine the distance to this plane according to the current estimation,
        Eq. \eqref{eq:observer:sensormodels:camera:origin} is solved for $\lambda$
        in accordance with Eq.~\eqref{eq:observer:sensormodels:camera:lambda}.
        \begin{align}
            \left\lbrace
            \begin{array}{ll}
                \varnothing_{\text{PTAM}} &= \xi + R(q^{wb}) r_{\text{camera}/\mathcal{G}} + \lambda R(q^{wP}) \frac{X^{PTAM}}{|X^{PTAM}|} \\
                \varnothing_{\text{PTAM}} \cdot \hat{z} &= 0
            \end{array}\right.
            \label{eq:observer:sensormodels:camera:origin}\\
%
            \lambda = -\frac{\left(\xi + R(q^{wb}) r_{\text{camera}/\mathcal{G}} \right) \cdot \hat{z}}{\left( R(q^{wP}) \frac{X^{PTAM}}{|X^{PTAM}|} \right) \cdot \hat{z}}
            \label{eq:observer:sensormodels:camera:lambda}
        \end{align}

        \fig{\plotwidth}{ground}{The PTAM coordinate system is assumed to be positioned at zero height. $\lambda$ is calculated as the estimated real-world distance to the PTAM coordinate system.}{fig:ground}


        With this definition, $\lambda$ corresponds to the approximated distance
        from the camera to the PTAM origin, in the metric world-fixed coordinate system.
        By comparing this approximation with the distance measured
        in the PTAM coordinate system, we obtain an estimate for the scaling factor, $s$, given
        in Eq.~\ref{eq:observer:camera:s}.
        \begin{equation}
        \label{eq:observer:camera:s}
            s = \frac{|X^{PTAM}|}{|\lambda|}
        \end{equation}

        Together, the parameters derived in this section describe the transformation
        connecting the PTAM reference frame to the metric world.
        For further refinement, these parameters could be inserted into the
        global observer filter - introducing eight new states containing
        $q^{Pw}$, $s$ and $\varnothing_{\text{cam}}$.% - although little benefit of this has been observed in simulated testing.
        Because the PTAM coordinate system is defined fixed in the global NEDEF coordinate system,
        the transform parameters would be static through the observer's time update.

    \subsubsection{Camera Measurements}
        \label{sssec:observer:sensormodels:camera:refinement}
        The camera measurement update is made separate from the update of the other sensors, using
        the measurement equations in \eqref{eq:observer:measurement:camera}, expanding the
        equation derived in Eqs. \eqref{eq:observer:sensormodels:camera:transformation} and \eqref{eq:observer:sensormodels:camera:qpw}.

        \begin{subequations}
            \label{eq:observer:measurement:camera}
            \begin{align}
                \hat{X}^{\text{PTAM}} &= \mathcal{J}^{Pw} (\xi + R(q^{wb})r_{\text{camera}/\mathcal{G}}) + e_{\text{PTAM,X}} \\
                \hat{q}^{\text{PTAM,c}} &= q^{Pw} q^{wb} q^{bc} + e_{\text{PTAM,q}}
            \end{align}
        \end{subequations}

    \subsubsection{Teleportation}
        \label{sssec:observer:sensormodels:camera:teleportation}
        The PTAM tracking may sometimes exhibit a ``teleporting'' behavior.
        That is, although tracking is overall stable, the origin may
        sometimes be misassociated and placed at a new position as the
        tracking gets lost.
        To detect this, the measurements may be monitored for sudden changes in position.
        If a teleportation is detected, a reinitialization would be needed,
        either performing a new initial estimation, or utilizing the previous state
        to recognize the new pose of the origin.
        The teleporting behavior is currently detected in the thesis implementation using simple thresholding,
        as in Eq.~\eqref{eq:observer:sensormodels:camera:teleport},
        although no action is currently implemented to recover.
        \begin{equation}
            \label{eq:observer:sensormodels:camera:teleport}
            \left|X^{\text{PTAM}}_{t} - X^{\text{PTAM}}_{t-1}\right| \cdot s > \epsilon
        \end{equation}
        The thresholded condition in Eq.~\eqref{eq:observer:sensormodels:camera:teleport}
        is scaled by the factor $s$ from the transformation, to achieve a metric comparison
        with the configurable parameter, $\epsilon$.
